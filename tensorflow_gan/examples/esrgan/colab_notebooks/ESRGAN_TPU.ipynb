{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "ESRGAN_TPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH5RikVCeczA"
      },
      "source": [
        "# **ESRGAN with TF-GAN**\n",
        "\n",
        "### **Overview**\n",
        "This notebook demonstrates the E2E process of data loading, preprocessing, training and evaluation of the [ESRGAN](https://arxiv.org/abs/1809.00219) model using Tensorflow and TF-GAN on TPUs. To understand the basics of TF-GAN and explore more features of the library, please visit [Tf-GAN tutorial](https://github.com/tensorflow/gan/blob/master/tensorflow_gan/examples/colab_notebooks/tfgan_tutorial.ipynb) notebook first. Please visit the [Google Cloud Tutorial](https://cloud.google.com/storage/docs/creating-buckets) to learn how to create and make use of a cloud storage bucket. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV9-ddGuZl6A"
      },
      "source": [
        "### **Learning Objectives**\n",
        "Through this Colab notebook you will learn how to :\n",
        "* Implement the ESRGAN model and train it\n",
        "* Make use of various TF-GAN functions to visualize and evaluate the results. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UbF4X9MIIje"
      },
      "source": [
        "### **Steps to run this notebook**\n",
        "\n",
        "\n",
        "* Click on the following icon to open this notebook in Google Colaboratory. \n",
        "\n",
        "> [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tensorflow/gan/tree/master/tensorflow_gan/examples/esrgan/colab_notebooks/ESRGAN_TPU.ipynb)\n",
        "\n",
        "* Create a Cloud Storage bucket for storage : http://console.cloud.google.com/storage.\n",
        "* Navigate to `Runtime > Change runtime type` tab \n",
        "* Select TPU from hardware accelerator and save\n",
        "* Click Connect in the upper right corner and select Connect to hosted runtime.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucHsfsHVxdlx"
      },
      "source": [
        "## Testing out the TPU connection\n",
        "First, you'll need to enable TPUs for the notebook.\n",
        "\n",
        "Navigate to Editâ†’Notebook Settings, and select TPU from the Hardware Accelerator drop-down (you can also access Notebook Settings via the command palette: cmd/ctrl-shift-P).\n",
        "\n",
        "Next, we'll check that we can connect to the TPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYYWk8hxg1L6"
      },
      "source": [
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "import pprint\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'Did you forget to switch to TPU?'\n",
        "tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "with tf.Session(tpu_address) as sess:\n",
        "  devices = sess.list_devices()\n",
        "pprint.pprint(devices)\n",
        "device_is_tpu = [True if 'TPU' in str(x) else False for x in devices]\n",
        "assert True in device_is_tpu, 'Did you forget to switch to TPU?'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YOdKMqSxhir"
      },
      "source": [
        "### Authentication\n",
        "\n",
        "To run on Google's free Cloud TPUs, you must set up a Google Cloud Storage bucket to store dataset and model weights during training. New customers to Google Cloud Platform can get $300 in free credits which can come in handy while running this notebook. \n",
        "\n",
        "Firstly enter the name of the cloud bucket you have created.\n",
        "For authentication you will be redirected to give Google Cloud SDK access to your cloud bucket. Paste the authentication code in text box below this cell and proceed.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVSswkFpg7jn"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import re\n",
        "import time\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_gcs_config\n",
        "\n",
        "# Google Cloud Storage bucket for storing the training dataset.\n",
        "bucket = '' #@param {type:\"string\"}\n",
        "\n",
        "assert bucket, 'Must specify an existing GCS bucket name'\n",
        "print('Using bucket: {}'.format(bucket))\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'Missing TPU; did you request a TPU in Notebook Settings?'\n",
        "tpu_address = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Upload credentials to TPU.\n",
        "tf.config.experimental_connect_to_host(tpu_address)\n",
        "tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "# Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7UvxZQ_xkyj"
      },
      "source": [
        "### Check imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_2_IDZV21ye"
      },
      "source": [
        "# Check that imports for the rest of the file work.\n",
        "import os\n",
        "import tensorflow as tf\n",
        "!pip install tensorflow-gan\n",
        "import tensorflow_gan as tfgan\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "# Allow matplotlib images to render immediately.\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOxTwUEp43xD"
      },
      "source": [
        "### **Training ESRGAN**\n",
        "The ESRGAN model proposed in the paper [ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks (Wang Xintao et al.)](https://arxiv.org/abs/1809.00219) performs the task of image super-resolution which is the process of reconstructing high resolution (HR) image from a given low resolution (LR) image. Please go through the paper to have a deeper understanding of the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj0cUphO2b8I"
      },
      "source": [
        "## Define Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2ONwB2d0egi"
      },
      "source": [
        " Params = {\n",
        "    'batch_size' : 32,                  # Number of image samples used in each training step          \n",
        "    'hr_dimension' : 256,               # Dimension of a High Resolution (HR) Image\n",
        "    'scale' : 4,                        # Factor by which Low Resolution (LR) Images will be downscaled.\n",
        "    'data_name': 'div2k/bicubic_x4',    # Dataset name - loaded using tfds.\n",
        "    'trunk_size' : 11,                  # Number of Residual blocks used in Generator,\n",
        "    'init_lr' : 0.00005,                # Initial Learning rate for networks. \n",
        "    'ph1_steps' : 10000,                # Number of steps required for phase-1 training\n",
        "    'ph2_steps' : 100000,               # Number of steps required for phase-2 training\n",
        "    'decay_ph1' : 0.2,                  # Factor by which learning rates are modified during phase-1 training \n",
        "    'decay_ph2' : 0.5,                  # Factor by which learning rates are modified during phase-2 training \n",
        "    'model_dir' : 'gs://{}/SavedModels' # Path to save the model after training. (inside the cloud bucket)\n",
        "                  .format(bucket),\n",
        "    'ckpt_dir' : '/content/ckpts/',     # Path to save the training checkpoints. (outside the cloud bucket)\n",
        "    'lambda' : 0.005,                   # To balance adversarial loss during phase-2 training. \n",
        "    'eta' : 0.01,                       # To balance L1 loss during phase-2 training.\n",
        "    'val_steps' : 100                   # Number of steps required for validation.\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFlwIkdgY_Gq"
      },
      "source": [
        "## Load Training Dataset\n",
        "We have used the [DIV2K](https://data.vision.ee.ethz.ch/cvl/DIV2K/) dataset which is usually used for benchmarking super resolution models. DIV2K dataset provides various kinds of image from which we are downloading only the HR images and corresponding LR images downsampled using bicubic downsampling. All the HR images are also scaled to 96 x 96 and LR images to 28 x 28.    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taZ6mKX0KMVT"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dataset_dir = 'gs://{}/{}'.format(bucket, 'datasets')\n",
        "\n",
        "def input_fn(mode, params):\n",
        "  assert 'batch_size' in params\n",
        "  bs = params['batch_size']\n",
        "  split = 'train' if mode == 'train' else 'validation'\n",
        "  shuffle = True \n",
        "\n",
        "  def scale(image, *args):\n",
        "    hr_size = params['hr_dimension']\n",
        "    scale = params['scale']\n",
        "\n",
        "    hr_image = image\n",
        "    hr_image = tf.image.resize(hr_image, [hr_size, hr_size])\n",
        "    lr_image = tf.image.resize(hr_image, [hr_size//scale, hr_size//scale], method='bicubic')\n",
        "    \n",
        "    hr_image = tf.clip_by_value(hr_image, 0, 255)\n",
        "    lr_image = tf.clip_by_value(lr_image, 0, 255)\n",
        "    \n",
        "    return lr_image, hr_image\n",
        "\n",
        "  dataset = (tfds.load(params['data_name'], split=split, data_dir=dataset_dir, as_supervised=True)\n",
        "             .map(scale, num_parallel_calls=4)\n",
        "             .cache()\n",
        "             .repeat())\n",
        "  if shuffle:\n",
        "    dataset = dataset.shuffle(\n",
        "        buffer_size=10000, reshuffle_each_iteration=True)\n",
        "  dataset = (dataset.batch(bs, drop_remainder=True)\n",
        "               .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "  \n",
        "  return dataset"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrsQ9z2qE5E1"
      },
      "source": [
        "train_ds = input_fn(mode='train', params=Params)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awduXPnxp1Si"
      },
      "source": [
        "## Visualize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdHhCwzL1qVx"
      },
      "source": [
        "img_lr, img_hr = next(iter(train_ds))\n",
        "lr = Image.fromarray(np.array(img_lr)[0].astype(np.uint8))\n",
        "lr = lr.resize([256, 256])\n",
        "display(lr)\n",
        "\n",
        "hr = Image.fromarray(np.array(img_hr)[0].astype(np.uint8))\n",
        "hr = hr.resize([256, 256])\n",
        "display(hr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn-qRzqi2vIZ"
      },
      "source": [
        "## Network Architecture\n",
        "The basic network buidling unit of the  ESRGAN is the Residual-in-Residual Block (RRDB) without batch normalization. The network implemented is similar to the architecture proposed in the paper.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ip4dwJxld1m"
      },
      "source": [
        "### Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyGCDSdH3WZR"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Add, Concatenate, Lambda, Flatten, Dense\n",
        "from keras.layers import LeakyReLU, Conv2D, BatchNormalization, Conv2DTranspose"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86KS2Dxm2hBg"
      },
      "source": [
        "def _conv_block(input, filters, activation=True):\n",
        "    h = Conv2D(filters, kernel_size=[3,3], kernel_initializer=\"he_normal\", bias_initializer=\"zeros\", strides=[1,1], padding='same', use_bias=True)(input)\n",
        "    if activation:\n",
        "        h = LeakyReLU(0.2)(h)\n",
        "    return h\n",
        "\n",
        "def dense_block(input):\n",
        "    h1 = _conv_block(input, 32)\n",
        "    h1 = Concatenate()([input, h1])\n",
        "\n",
        "    h2 = _conv_block(h1, 32)\n",
        "    h2 = Concatenate()([input, h1, h2])\n",
        "\n",
        "    h3 = _conv_block(h2, 32)\n",
        "    h3 = Concatenate()([input, h1, h2, h3])\n",
        "\n",
        "    h4 = _conv_block(h3, 32)\n",
        "    h4 = Concatenate()([input, h1, h2, h3, h4])  \n",
        "\n",
        "    h5 = _conv_block(h4, 32, activation=False)\n",
        "    \n",
        "    h5 = Lambda(lambda x: x * 0.2)(h5)\n",
        "    h = Add()([h5, input])\n",
        "    \n",
        "    return h\n",
        "\n",
        "def RRDB(input):\n",
        "    h = dense_block(input)\n",
        "    h = dense_block(h)\n",
        "    h = dense_block(h)\n",
        "    h = Lambda(lambda x:x * 0.2)(h)\n",
        "    out = Add()([h, input])\n",
        "    return out\n",
        "\n",
        "def upsample(x, filters):\n",
        "  x = Conv2DTranspose(filters, kernel_size=3, strides=2, padding='same', use_bias = True)(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  return x\n",
        "\n",
        "def ESRGAN_G(filter=32, trunk_size=Params['trunk_size'], out_channels=3):\n",
        "    lr_input = Input(shape=(None, None, 3))\n",
        "    \n",
        "    x = Conv2D(filter, kernel_size=[3,3], strides=[1,1], padding='same', use_bias=True)(lr_input)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "\n",
        "    ref = x\n",
        "    \n",
        "    for i in range(trunk_size):\n",
        "        x = RRDB(x)\n",
        "\n",
        "    x = Conv2D(filter, kernel_size=[3,3], strides=[1,1], padding='same', use_bias = True)(x)\n",
        "    x = Add()([x, ref])\n",
        "\n",
        "    x = upsample(x, filter)\n",
        "    x = upsample(x, filter)\n",
        "    \n",
        "    x = Conv2D(filter, kernel_size=3, strides=1, padding='same', use_bias=True)(x)\n",
        "    x = LeakyReLU(0.2)(x)\n",
        "    hr_output = Conv2D(out_channels, kernel_size=3, strides=1, padding='same', use_bias=True)(x)\n",
        "\n",
        "    model = Model(inputs=lr_input, outputs=hr_output)\n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDDlyS0k2uEI"
      },
      "source": [
        "### Discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTpSYNKg2xvM"
      },
      "source": [
        "def _conv_block_d(x, out_channel):\n",
        "  x = Conv2D(out_channel, 3,1, padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization(momentum=0.8)(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "  x = Conv2D(out_channel, 4,2, padding='same', use_bias=False)(x)\n",
        "  x = BatchNormalization(momentum=0.8)(x)\n",
        "  x = LeakyReLU(alpha=0.2)(x)\n",
        "  return x\n",
        "\n",
        "def ESRGAN_D(filters = 64, training=True):\n",
        "    img = Input(shape = (Params['hr_dimension'], Params['hr_dimension'], 3))\n",
        "    \n",
        "    x = Conv2D(filters, [3,3], 1, padding='same', use_bias=False)(img)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(filters, [3,3], 2, padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = _conv_block_d(x, filters *2)\n",
        "    x = _conv_block_d(x, filters *4)\n",
        "    x = _conv_block_d(x, filters *8)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(100)(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dense(1)(x)\n",
        "\n",
        "    model = Model(inputs = img, outputs = x)\n",
        "    return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AhbjnB53kA_"
      },
      "source": [
        "## Loss Functions\n",
        "The ESRGAN model makes use of three loss functions - pixel loss, perceptual loss (vgg_loss) and adversarial loss. Perceptual loss is calculated using the pre-trained VGG-19 network. Adversarial loss is separately calculated for both generator (relativistic_avg_loss_g) and discriminator (relativistic_avg_loss_d) using relativistic discriminator discussed in the paper. \n",
        "\n",
        "These loss functions ensures the balance between visual quality and metrics such as PSNR and encorages the generator to produce more realistic images with natural textures.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-2PD8E02xws"
      },
      "source": [
        "def pixel_loss(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    return tf.reduce_mean(tf.reduce_mean(tf.abs(y_true - y_pred), axis = 0))\n",
        "\n",
        "# Functions for calculating adversarial loss. \n",
        "def ragan_discriminator_loss(d_real, d_fake):\n",
        "  def get_logits(x, y):\n",
        "    return x - tf.reduce_mean(y)\n",
        "  \n",
        "  real_logits = get_logits(d_real, d_fake)\n",
        "  fake_logits = get_logits(d_fake, d_real)\n",
        "\n",
        "  real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "          labels=tf.ones_like(real_logits), logits=real_logits))\n",
        "  fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "      labels=tf.zeros_like(fake_logits), logits=fake_logits))\n",
        "\n",
        "  return real_loss + fake_loss\n",
        "\n",
        "def ragan_generator_loss(d_real, d_fake):\n",
        "  real_logits = d_real - tf.reduce_mean(d_fake)\n",
        "  fake_logits = d_fake - tf.reduce_mean(d_real)\n",
        "  \n",
        "  real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "      labels=tf.zeros_like(real_logits), logits=real_logits))  \n",
        "  fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "      labels=tf.ones_like(fake_logits), logits=fake_logits))\n",
        "\n",
        "  return real_loss + fake_loss\n",
        "  \n",
        "# Function for calculating perceptual loss\n",
        "def vgg_loss(weight=None, input_shape=None):\n",
        "  vgg_model = tf.keras.applications.vgg19.VGG19(\n",
        "      input_shape=input_shape, weights=weight, include_top=False\n",
        "  )\n",
        "\n",
        "  for layer in vgg_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  vgg_model.get_layer(\"block5_conv4\").activation = lambda x: x\n",
        "  vgg = tf.keras.Model(\n",
        "      inputs=[vgg_model.input],\n",
        "      outputs=[vgg_model.get_layer(\"block5_conv4\").output])\n",
        "\n",
        "  def loss(y_true, y_pred):\n",
        "      return tf.compat.v1.losses.absolute_difference(vgg(y_true), vgg(y_pred))\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12v-12pc3njS"
      },
      "source": [
        "## Training\n",
        "ESRGAN model is trained in two phases in which the first phase deals with training the generator network individually and is aimed at improving the PSNR values of generated images by reducing the L1 loss. \n",
        "\n",
        "If starting from scratch, phase-1 training can be completed within an hour on free colab TPU, whereas phase-2 can take around 2-3 hours to get good results. As a result saving the weights/checkpoints are important steps during training. \n",
        "\n",
        "Training of the same generator model is continued in the second phase along with the discriminator network. In the second phase, the generator reduces the L1 Loss, Relativistic average GAN (RaGAN) loss which indicates how realistic does the generated image look and the imporved Perceptual loss proposed in the paper.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obdWWOA43pfI"
      },
      "source": [
        "# To display images in the order : LR Image -> Generated Image -> HR Image\n",
        "def visualize_results(image_lr, generated, image_hr):\n",
        "    size = 180\n",
        "    resized_lr = tf.image.resize(image_lr, [size, size], method=tf.image.ResizeMethod.BILINEAR)\n",
        "    resized_gen = tf.image.resize(generated, [size, size], method=tf.image.ResizeMethod.BILINEAR)\n",
        "    resized_hr = tf.image.resize(image_hr, [size, size], method=tf.image.ResizeMethod.BILINEAR)\n",
        "    stack = tf.stack([resized_lr[0], resized_gen[0], resized_hr[0]])\n",
        "    image_grid = tfgan.eval.python_image_grid(stack, grid_shape=(1, 3))\n",
        "    result = Image.fromarray(image_grid.astype(np.uint8))\n",
        "    return result"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b2MrAN6HnJB"
      },
      "source": [
        "# Define the TPU strategy\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj62P3o5hDdN"
      },
      "source": [
        "train_ds = iter(strategy.experimental_distribute_dataset(train_ds))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2QaHb833tSP"
      },
      "source": [
        "### Phase - 1 Training\n",
        "\n",
        "Steps Involved:\n",
        "\n",
        "* Define the generator and its optimizer. \n",
        "* Take LR, HR image pairs from the training dataset\n",
        "* Input the LR image to the generator network\n",
        "* Calculate the L1 loss using the generated image and HR image\n",
        "* Calculate gradient value and apply it to the optimizer\n",
        "* Update the learning rate of optimizer after every decay steps for better performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "558CP0be3qO8"
      },
      "source": [
        "with strategy.scope():\n",
        "  metric = tf.keras.metrics.Mean()\n",
        "  psnr_metric = tf.keras.metrics.Mean()\n",
        "\n",
        "  generator = ESRGAN_G()\n",
        "\n",
        "  G_optimizer = tf.optimizers.Adam(\n",
        "      learning_rate = 0.0002,\n",
        "      beta_1 = 0.9,\n",
        "      beta_2 = 0.99\n",
        "  )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjo26ZY13qR9"
      },
      "source": [
        "@tf.function\n",
        "def train_step(image_lr, image_hr):\n",
        "  with tf.GradientTape() as tape:\n",
        "    fake = generator(image_lr)\n",
        "    loss = pixel_loss(image_hr, fake) * (1.0 / Params['batch_size'])\n",
        "    psnr_value = tf.image.psnr(fake, image_hr,max_val = 256.0)\n",
        " \n",
        "    metric(loss)\n",
        "\n",
        "    gradient = tape.gradient(loss, generator.trainable_variables)\n",
        "    G_optimizer.apply_gradients(zip(gradient, generator.trainable_variables))\n",
        "\n",
        "    return psnr_value\n",
        "\n",
        "def val_steps(image_lr, image_hr):\n",
        "  fake = generator(image_lr)\n",
        "  result = visualize_results(image_lr, fake, image_hr)\n",
        "  display(result)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvHI7PpE3qVR"
      },
      "source": [
        "step_count = 0\n",
        "\n",
        "while step_count < Params['ph1_steps']:\n",
        "  lr, hr = next(train_ds)\n",
        "  psnr_loss = strategy.run(train_step, args = (lr, hr))\n",
        "  loss = strategy.reduce(tf.distribute.ReduceOp.MEAN, psnr_loss, axis=None)\n",
        "  psnr_metric(loss)\n",
        "  \n",
        "  if step_count%1000 == 0:\n",
        "    lr = np.array(lr.values)[0]\n",
        "    hr = np.array(hr.values)[0]\n",
        "    print(\"step {}      PNSR = {}\".format(step_count, psnr_metric.result()))\n",
        "    val_steps(lr, hr) \n",
        "  \n",
        "  if step_count%5000 == 0:\n",
        "    G_optimizer.learning_rate.assign(\n",
        "        G_optimizer.learning_rate * Params['decay_ph1'])  \n",
        "  step_count+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzn4SNSCRCTs"
      },
      "source": [
        "# Save the generator network which is then used for phase-2 training\n",
        "os.makedirs(Params['model_dir'] + '/Phase_1/generator', exist_ok = True)\n",
        "generator.save(Params['model_dir'] + '/Phase_1/generator')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JFXfCKX31LL"
      },
      "source": [
        "###**Phase - 2**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Loc1wcMP93d9"
      },
      "source": [
        "#### Define optimizers and load networks\n",
        " * Generator network trained in Phase 1 is loaded.\n",
        " * Checkpoints are also defined which can be useful during training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlN5EumYRTJl"
      },
      "source": [
        "with strategy.scope():\n",
        "  optimizer = tf.optimizers.Adam(\n",
        "      learning_rate = 0.0002,\n",
        "      beta_1 = 0.9,\n",
        "      beta_2 = 0.99\n",
        "  )\n",
        "  generator = tf.keras.models.load_model(Params['model_dir'] + '/Phase_1/generator/')\n",
        "  discriminator = ESRGAN_D()\n",
        "\n",
        "  G_optimizer = optimizer\n",
        "  G_optimizer.learning_rate.assign(0.00005)\n",
        "  D_optimizer = optimizer\n",
        "\n",
        "  checkpoint = tf.train.Checkpoint(G=generator,\n",
        "                                   D = discriminator,\n",
        "                                   G_optimizer=G_optimizer,\n",
        "                                   D_optimizer=D_optimizer)\n",
        "  local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvBvzhVd9S3s"
      },
      "source": [
        "#### Load VGG weights\n",
        "The VGG-19 network pretrained on imagenet is loaded for calculating perceptual loss. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7kAhmk_mZ2D"
      },
      "source": [
        "with strategy.scope():\n",
        "  perceptual_loss = vgg_loss(\n",
        "        weight = \"imagenet\",\n",
        "        input_shape = [Params['hr_dimension'], Params['hr_dimension'], 3])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn9IDUJymZ46"
      },
      "source": [
        "with strategy.scope():\n",
        "  gen_metric = tf.keras.metrics.Mean()\n",
        "  disc_metric = tf.keras.metrics.Mean()\n",
        "  psnr_metric = tf.keras.metrics.Mean()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97PQOUZw9qAQ"
      },
      "source": [
        "#### Training step\n",
        "* Input the LR image to the generator network\n",
        "* Calculate L1 loss, perceptual loss and adversarial loss for both generator and discriminator.\n",
        "* Update the optimizers for both networks using the obtained gradient values\n",
        "* Update the learning rate of optimizers after every decay steps for better performance\n",
        "* TF-GAN's image grid function is used to display the generated images in the validation steps. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8ka2bnGmZ7l"
      },
      "source": [
        "@tf.function\n",
        "def train_step(image_lr, image_hr):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "     fake = generator(image_lr)\n",
        "     \n",
        "     percep_loss = tf.reduce_mean(perceptual_loss(image_hr, fake))\n",
        "     l1_loss = pixel_loss(image_hr, fake) \n",
        "     \n",
        "     real_logits = discriminator(image_hr) \n",
        "     fake_logits = discriminator(fake) \n",
        "     loss_RaG = ragan_generator_loss(real_logits, fake_logits) \n",
        "     disc_loss = ragan_discriminator_loss(real_logits, fake_logits) \n",
        "     \n",
        "     gen_loss = percep_loss + Params['lambda'] * loss_RaG + Params['eta'] * l1_loss\n",
        "\n",
        "     gen_loss = gen_loss / Params['batch_size']\n",
        "     disc_loss = disc_loss / Params['batch_size']     \n",
        "     psnr_loss = tf.image.psnr(fake, image_hr, max_val = 256.0)\n",
        "     \n",
        "     disc_metric(disc_loss) \n",
        "     gen_metric(gen_loss)\n",
        "     psnr_metric(psnr_loss)\n",
        "     \n",
        "     disc_grad = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "     D_optimizer.apply_gradients(zip(disc_grad, discriminator.trainable_variables))\n",
        "\n",
        "     gen_grad = gen_tape.gradient(gen_loss, generator.trainable_variables) \n",
        "     G_optimizer.apply_gradients(zip(gen_grad, generator.trainable_variables))\n",
        "     \n",
        "     return [disc_loss, gen_loss, psnr_loss]\n",
        "\n",
        "def val_step(image_lr, image_hr):\n",
        "  fake = generator(image_lr)\n",
        "  result = visualize_results(image_lr, fake, image_hr)\n",
        "  display(result)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKtenGfcmZ9Q"
      },
      "source": [
        "step_count = 0\n",
        "decay_step = [9000, 30000, 50000]\n",
        "\n",
        "while step_count < Params['ph2_steps']:\n",
        "  lr, hr = next(train_ds)\n",
        "  \n",
        "  if tf.train.latest_checkpoint(Params['ckpt_dir']): \n",
        "    checkpoint.restore(tf.train.latest_checkpoint(Params['ckpt_dir']))\n",
        "  \n",
        "  disc_loss, gen_loss, psnr_loss  = strategy.run(train_step, args = (lr, hr))\n",
        "  \n",
        "  if step_count % 1000 == 0:\n",
        "    print(\"step {}\".format(step_count) + \"   Generator Loss = {}   \".format(gen_metric.result()) + \n",
        "          \"Disc Loss = {}\".format(disc_metric.result()) + \"   PSNR : {}\".format(psnr_metric.result()))\n",
        "    \n",
        "    lr = np.array(lr.values)[0]\n",
        "    hr = np.array(hr.values)[0]\n",
        "    val_step(lr, hr)\n",
        "  \n",
        "  checkpoint.write(Params['ckpt_dir'], options=local_device_option)\n",
        "  step_count+=1\n",
        "  \n",
        "  if step_count >= decay_step[0]:\n",
        "    decay_step.pop(0)\n",
        "    G_optimizer.learning_rate.assign(\n",
        "            G_optimizer.learning_rate * Params['decay_ph2'])\n",
        "  \n",
        "    D_optimizer.learning_rate.assign(\n",
        "        D_optimizer.learning_rate * Params['decay_ph2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTOoaeB1-3jf"
      },
      "source": [
        "os.makedirs(Params['model_dir'] + '/Phase_2/generator', exist_ok = True)\n",
        "os.makedirs(Params['model_dir'] + '/Phase_2/discriminator', exist_ok = True)\n",
        "\n",
        "generator.save(Params['model_dir'] + '/Phase_2/generator')\n",
        "discriminator.save(Params['model_dir'] + '/Phase_2/discriminator')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvsFKLtVucAT"
      },
      "source": [
        "## Network Interpolation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRD8c9VougNP"
      },
      "source": [
        "def network_interpolation(alpha=0.2,\n",
        "                          phase_1_path=None,\n",
        "                          phase_2_path=None):\n",
        "  psnr_gen = tf.keras.model.load_model(phase_1_path)\n",
        "  gan_gen = tf.keras.models.load_model(phase_2_path)\n",
        "\n",
        "  for var_1, var_2 in zip(gan_gen.trainable_variables, \n",
        "                          psnr_gen.trainable_variables):\n",
        "    var_1.assign((1 - alpha) * var_2 + alpha * var_1)\n",
        "\n",
        "  return gan_gen"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QAg-xesu_Zz"
      },
      "source": [
        "generator = network_interpolation(phase_1_path = Params['model_dir'] + '/Phase_1/generator',\n",
        "                                  phase_2_path = Params['model_dir'] + '/Phase_2/generator')\n",
        "generator.save(Params['model_dir'] + '/InterpolatedGenerator/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqVzpGelUok3"
      },
      "source": [
        "## Evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmXYUDSMO9iZ"
      },
      "source": [
        "val_ds = input_fn(mode='validation', params=Params)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fSRrBM9ROIe"
      },
      "source": [
        "### Visualize Generated Images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xBGl7bQkTgW"
      },
      "source": [
        "def val_steps(image_lr, image_hr):\n",
        "  fake = generator(image_lr)\n",
        "  result = visualize_results(image_lr, fake, image_hr)\n",
        "  display(result)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GEvV0mkOWpv"
      },
      "source": [
        "for i in range(3):\n",
        "  lr, hr = next(iter(val_ds))\n",
        "  val_steps(lr, hr) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1qe5HLPqoQE"
      },
      "source": [
        "FID and Inception Scores are two common metrices used to evaluate the performance of a GAN model and PSNR value is used to quantify the similarity between two images and is used for benchmarking super resolution models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKWy28qSsUKQ"
      },
      "source": [
        "@tf.function\n",
        "def get_fid_score(real_image, gen_image):\n",
        "  size = tfgan.eval.INCEPTION_DEFAULT_IMAGE_SIZE\n",
        "\n",
        "  resized_real_images = tf.image.resize(real_image, [size, size], method=tf.image.ResizeMethod.BILINEAR)\n",
        "  resized_generated_images = tf.image.resize(gen_image, [size, size], method=tf.image.ResizeMethod.BILINEAR)\n",
        "  \n",
        "  num_inception_images = 1\n",
        "  num_batches = Params['batch_size'] // num_inception_images\n",
        "  \n",
        "  fid = tfgan.eval.frechet_inception_distance(resized_real_images, resized_generated_images, num_batches=num_batches)\n",
        "  return fid\n",
        "  \n",
        "@tf.function\n",
        "def get_inception_score(images, gen, num_inception_images = 8):\n",
        "  size = tfgan.eval.INCEPTION_DEFAULT_IMAGE_SIZE\n",
        "  resized_images = tf.image.resize(images, [size, size], method=tf.image.ResizeMethod.BILINEAR)\n",
        "\n",
        "  num_batches = Params['batch_size'] // num_inception_images\n",
        "  inc_score = tfgan.eval.inception_score(resized_images, num_batches=num_batches)\n",
        "\n",
        "  return inc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CsP925UsUfI"
      },
      "source": [
        "with strategy.scope():\n",
        "  generator = tf.keras.models.load_model(Params['model_dir'] + '/InterpolatedGenerator')\n",
        "\n",
        "  fid_metric = tf.keras.metrics.Mean()\n",
        "  inc_metric = tf.keras.metrics.Mean()\n",
        "  psnr_metric = tf.keras.metrics.Mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI4xmkEqsZX9"
      },
      "source": [
        "count = 0\n",
        "i = 0\n",
        "while i < Params['val_steps']: \n",
        "  lr, hr = next(iter(val_ds))\n",
        "\n",
        "  gen = generator(lr)\n",
        "  \n",
        "  fid = strategy.run(get_fid_score, args = (hr, gen))\n",
        "  real_is = strategy.run(get_inception_score, args=(hr, gen))\n",
        "  gen_is = strategy.run(get_inception_score, args=(gen, hr))\n",
        "  val_steps(lr, hr) \n",
        "\n",
        "  fid_metric(fid)\n",
        "  inc_metric(gen_is)\n",
        "  psnr_metric(tf.reduce_mean(tf.image.psnr(gen, hr, max_val = 256.0)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}